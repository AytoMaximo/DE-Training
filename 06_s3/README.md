## Ссылка на видеозащиту проекта
[Видео на YouTube](https://youtu.be/GXSbJXEwB4s)

## Описание проекта
Данный проект представляет собой обработку данных с использованием Python. Основные задачи включают:
- Мониторинг новых файлов в директории.
- Фильтрацию и обработку данных.
- Сохранение обработанных файлов во временную директорию.
- Загрузку обработанных файлов в хранилище.
- Архивацию исходных файлов.

## Структура проекта
- `task_6_4/src/` — скрипты, обеспечивающие пайплайн.
- `task_6_4/incoming/` — директория для входящих файлов.
- `task_6_4/temp/` — временная директория для обработанных файлов.
- `task_6_4/archive/` — директория для архивированных файлов.
- `task_6_4/pipeline.log` — лог-файл, содержащий информацию о выполнении операций.
- `selectel_api.py` — класс для работы с S3.
- `main.py` — точка входа.

## Основные этапы обработки
1. **Обнаружение нового файла**: Система отслеживает появление новых файлов в директории `incoming/`.
2. **Обработка файла**: Данные фильтруются и сохраняются в директорию `temp/`.
3. **Загрузка файла**: Обработанный файл загружается в хранилище Selectel S3.
4. **Архивация**: Исходный файл перемещается в директорию `archive/`.
5. **Логирование**: Все этапы фиксируются в лог-файле `pipeline.log`.

## Запуск
Для запуска обработки выполните:
```bash
python main.py
```
Для генерации тестового CSV файла:
```bash
python csv_generator.py --output-dir ../incoming --rows 200 --files 1
```

## Логирование
Все события записываются в файл `pipeline.log` с указанием времени, типа события и описания.
